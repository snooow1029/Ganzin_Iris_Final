import os
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms, models
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm
import random
from torchvision.models import resnet50, googlenet

class IrisDataset(Dataset):
    def __init__(self, mode='train', transform=None):
        """
        è™¹è†œéªŒè¯æ•°æ®é›†åŠ è½½å™¨
        
        å‚æ•°:
            mode (str): 'train' æˆ– 'test'
            transform: å›¾åƒé¢„å¤„ç†æ“ä½œ
        """
        self.mode = mode
        self.transform = transform
        self.images = []           # å­˜å‚¨å›¾ç‰‡è·¯å¾„
        self.subject_ids = []      # å­˜å‚¨äººç‰©ID
        self.subject_to_images = {}  # æ˜ å°„subject_idåˆ°å›¾åƒè·¯å¾„åˆ—è¡¨
        
        # åŸºç¡€è·¯å¾„
        base_path = r"D:\å®¶æ„·çš„è³‡æ–™\å¤§å­¸\å¤§ä¸‰\é›»è…¦è¦–è¦º\final\Ganzin_supplement4student\dataset"
        
        # åŠ è½½CASIA-Iris-Lampæ•°æ®é›†
        lamp_path = os.path.join(base_path, "CASIA-Iris-Lamp")
        self._load_lamp_dataset(lamp_path)
        
        # åŠ è½½CASIA-Iris-Thousandæ•°æ®é›†
        thousand_path = os.path.join(base_path, "CASIA-Iris-Thousand")
        self._load_thousand_dataset(thousand_path)
        
        # åŠ è½½Ganzin-J7EF-Gazeæ•°æ®é›†
        gaze_path = os.path.join(base_path, "Ganzin-J7EF-Gaze")
        self._load_gaze_dataset(gaze_path)
        
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆ - {mode} æ¨¡å¼")
        print(f"æ ·æœ¬æ•°é‡: {len(self.images)}")
        print(f"äººæ•°: {len(self.subject_to_images)}")
    
    def _load_lamp_dataset(self, lamp_path):
        """åŠ è½½CASIA-Iris-Lampæ•°æ®é›†"""
        if not os.path.exists(lamp_path):
            print(f"è·¯å¾„ä¸å­˜åœ¨: {lamp_path}")
            return
            
        for subject_id in os.listdir(lamp_path):
            subject_path = os.path.join(lamp_path, subject_id)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶å¤¹
            if not os.path.isdir(subject_path):
                continue
            
            # æ£€æŸ¥æ˜¯è®­ç»ƒé›†è¿˜æ˜¯æµ‹è¯•é›†
            subject_id_num = int(subject_id)
            is_test = (1 <= subject_id_num <= 80)
            
            # å¦‚æœæ¨¡å¼ä¸æ•°æ®é›†ä¸åŒ¹é…åˆ™è·³è¿‡
            if (self.mode == 'train' and is_test) or (self.mode == 'test' and not is_test):
                continue
            
            # åˆå§‹åŒ–æ­¤äººçš„å›¾åƒåˆ—è¡¨
            if subject_id not in self.subject_to_images:
                self.subject_to_images[subject_id] = []
            
            # åŠ è½½å·¦å³çœ¼å›¾åƒ
            for eye in ['L', 'R']:
                eye_path = os.path.join(subject_path, eye)
                if os.path.exists(eye_path):
                    for img_name in os.listdir(eye_path):
                        if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                            img_path = os.path.join(eye_path, img_name)
                            self.images.append(img_path)
                            self.subject_ids.append(subject_id)
                            self.subject_to_images[subject_id].append(img_path)
    
    def _load_thousand_dataset(self, thousand_path):
        """åŠ è½½CASIA-Iris-Thousandæ•°æ®é›†"""
        if not os.path.exists(thousand_path):
            print(f"è·¯å¾„ä¸å­˜åœ¨: {thousand_path}")
            return
            
        for subject_id in os.listdir(thousand_path):
            subject_path = os.path.join(thousand_path, subject_id)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶å¤¹
            if not os.path.isdir(subject_path):
                continue
            
            # æ£€æŸ¥æ˜¯è®­ç»ƒé›†è¿˜æ˜¯æµ‹è¯•é›†
            subject_id_num = int(subject_id)
            is_test = (0 <= subject_id_num <= 199)
            
            # å¦‚æœæ¨¡å¼ä¸æ•°æ®é›†ä¸åŒ¹é…åˆ™è·³è¿‡
            if (self.mode == 'train' and is_test) or (self.mode == 'test' and not is_test):
                continue
            
            # åˆå§‹åŒ–æ­¤äººçš„å›¾åƒåˆ—è¡¨
            if subject_id not in self.subject_to_images:
                self.subject_to_images[subject_id] = []
            
            # åŠ è½½å·¦å³çœ¼å›¾åƒ
            for eye in ['L', 'R']:
                eye_path = os.path.join(subject_path, eye)
                if os.path.exists(eye_path):
                    for img_name in os.listdir(eye_path):
                        if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                            img_path = os.path.join(eye_path, img_name)
                            self.images.append(img_path)
                            self.subject_ids.append(subject_id)
                            self.subject_to_images[subject_id].append(img_path)
    
    def _load_gaze_dataset(self, gaze_path):
        """åŠ è½½Ganzin-J7EF-Gazeæ•°æ®é›†"""
        if not os.path.exists(gaze_path):
            print(f"è·¯å¾„ä¸å­˜åœ¨: {gaze_path}")
            return
            
        for subject_id in os.listdir(gaze_path):
            subject_path = os.path.join(gaze_path, subject_id)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶å¤¹
            if not os.path.isdir(subject_path):
                continue
            
            # åˆå§‹åŒ–æ­¤äººçš„å›¾åƒåˆ—è¡¨
            if subject_id not in self.subject_to_images:
                self.subject_to_images[subject_id] = []
            
            # åŠ è½½å·¦å³çœ¼å›¾åƒ
            for eye in ['L', 'R']:
                eye_path = os.path.join(subject_path, eye)
                if os.path.exists(eye_path):
                    for img_name in os.listdir(eye_path):
                        if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                            # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•é›†
                            is_test = False
                            if eye == 'L' and 'view_3' in img_name:
                                is_test = True
                            elif eye == 'R' and 'view_2' in img_name:
                                is_test = True
                                
                            # å¦‚æœæ¨¡å¼ä¸æ•°æ®é›†ä¸åŒ¹é…åˆ™è·³è¿‡
                            if (self.mode == 'train' and is_test) or (self.mode == 'test' and not is_test):
                                continue
                                
                            img_path = os.path.join(eye_path, img_name)
                            self.images.append(img_path)
                            self.subject_ids.append(subject_id)
                            self.subject_to_images[subject_id].append(img_path)
    
    def __len__(self):
        # æˆ‘ä»¬å¯ä»¥ç”Ÿæˆçš„ä¸åŒå›¾åƒå¯¹æ•°é‡
        # è¿™é‡Œç®€å•è®¾ä¸ºå›¾åƒæ€»æ•°ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨__getitem__ä¸­ä¼šéšæœºç”Ÿæˆå›¾åƒå¯¹
        return len(self.images)
    
    def __getitem__(self, idx):
        # éšæœºå†³å®šæ˜¯ç”Ÿæˆç›¸åŒäººçš„å›¾åƒå¯¹è¿˜æ˜¯ä¸åŒäººçš„å›¾åƒå¯¹
        same_person = random.random() > 0.5
        
        if same_person:
            # é€‰ä¸€ä¸ªæœ‰è‡³å°‘ä¸¤å¼ ç…§ç‰‡çš„äºº
            valid_subjects = [subj for subj, imgs in self.subject_to_images.items() if len(imgs) >= 2]
            if not valid_subjects:
                # å¦‚æœæ²¡æœ‰äººæœ‰å¤šå¼ ç…§ç‰‡ï¼Œæ”¹ä¸ºé€‰æ‹©ä¸åŒäºº
                same_person = False
            else:
                # é€‰æ‹©ä¸€ä¸ªäºº
                subject_id = random.choice(valid_subjects)
                # ä»è¿™ä¸ªäººçš„å›¾åƒä¸­éšæœºé€‰æ‹©ä¸¤å¼ ä¸åŒçš„å›¾åƒ
                img_paths = random.sample(self.subject_to_images[subject_id], 2)
        
        if not same_person:
            # é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„äºº
            subject_ids = random.sample(list(self.subject_to_images.keys()), 2)
            # ä»æ¯ä¸ªäººä¸­éšæœºé€‰æ‹©ä¸€å¼ å›¾åƒ
            img_paths = [random.choice(self.subject_to_images[subject_ids[0]]),
                        random.choice(self.subject_to_images[subject_ids[1]])]
        
        # åŠ è½½å¹¶è½¬æ¢å›¾åƒ
        try:
            images = []
            for img_path in img_paths:
                image = Image.open(img_path).convert('RGB')
                if self.transform:
                    image = self.transform(image)
                images.append(image)
            
            # åˆ›å»ºæ ‡ç­¾: 1è¡¨ç¤ºç›¸åŒäººï¼Œ0è¡¨ç¤ºä¸åŒäºº
            label = torch.tensor(1.0 if same_person else 0.0, dtype=torch.float)
            
            return images[0], images[1], label
        except Exception as e:
            print(f"Error loading images: {e}")
            # é€’å½’è°ƒç”¨ï¼Œé‡æ–°éšæœºé€‰æ‹©
            return self.__getitem__(random.randint(0, len(self) - 1))


class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        # ä½¿ç”¨é¢„è®­ç»ƒçš„GoogLeNetä½œä¸ºç‰¹å¾æå–å™¨
        googlenet = models.googlenet(pretrained=True)
        # ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚
        self.feature_extractor = nn.Sequential(*list(googlenet.children())[:-2])
        # æ·»åŠ å…¨å±€å¹³å‡æ± åŒ–
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        # æ·»åŠ å…¨è¿æ¥å±‚æ¥æ¯”è¾ƒç‰¹å¾å‘é‡
        self.fc = nn.Sequential(
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 1)
        )
    
    def forward_one(self, x):
        # æå–ç‰¹å¾
        x = self.feature_extractor(x)
        # å…¨å±€æ± åŒ–
        x = self.avg_pool(x)
        # å±•å¹³
        x = x.view(x.size(0), -1)
        return x
    
    def forward(self, x1, x2):
        # è·å–ä¸¤å¼ å›¾åƒçš„ç‰¹å¾è¡¨ç¤º
        feat1 = self.forward_one(x1)
        feat2 = self.forward_one(x2)
        
        # è®¡ç®—ç‰¹å¾å·®å¼‚
        diff = torch.abs(feat1 - feat2)
        
        # é€šè¿‡å…¨è¿æ¥å±‚å¤„ç†å·®å¼‚
        out = self.fc(diff)
        
        # åº”ç”¨sigmoidæ¿€æ´»å‡½æ•°ï¼Œè¾“å‡ºç›¸ä¼¼æ€§å¾—åˆ†ï¼ˆ0-1ä¹‹é—´ï¼‰
        return torch.sigmoid(out)

class ContrastiveLoss(nn.Module):
    """
    å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œç”¨äºè®­ç»ƒå­ªç”Ÿç½‘ç»œ
    """
    def __init__(self, margin=1.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin
    
    def forward(self, output, label):
        # å¯¹æ¯”æŸå¤±
        # outputæ˜¯ç½‘ç»œè¾“å‡ºçš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ä¹‹é—´ï¼‰
        # labelæ˜¯1è¡¨ç¤ºç›¸åŒäººï¼Œ0è¡¨ç¤ºä¸åŒäºº
        
        # è®¡ç®—æ¬§æ°è·ç¦»
        euclidean_distance = 1 - output  # è½¬æ¢ç›¸ä¼¼åº¦åˆ°è·ç¦»
        
        # å¯¹æ¯”æŸå¤±å…¬å¼
        # å¯¹äºç›¸åŒç±»åˆ«ï¼Œæˆ‘ä»¬å¸Œæœ›è·ç¦»å°ï¼›å¯¹äºä¸åŒç±»åˆ«ï¼Œæˆ‘ä»¬å¸Œæœ›è·ç¦»å¤§äºmargin
        loss_contrastive = (label * euclidean_distance**2) + \
                          ((1 - label) * torch.clamp(self.margin - euclidean_distance, min=0)**2)
        
        return loss_contrastive.mean()


def get_data_loaders(batch_size=32, val_split=0.1):
    """
    åˆ›å»ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨
    
    å‚æ•°:
        batch_size (int): æ‰¹æ¬¡å¤§å°
        val_split (float): éªŒè¯é›†æ¯”ä¾‹
    
    è¿”å›:
        train_loader, val_loader, test_loader
    """
    # å®šä¹‰å›¾åƒé¢„å¤„ç†
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = IrisDataset(mode='train', transform=train_transform)
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int((1 - val_split) * len(train_dataset))
    val_size = len(train_dataset) - train_size
    train_subset, val_subset = random_split(train_dataset, [train_size, val_size])
    
    # åˆ›å»ºæµ‹è¯•é›†
    test_dataset = IrisDataset(mode='test', transform=test_transform)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)
    
    return train_loader, val_loader, test_loader


import os

def train_siamese_network(learning_rate=0.0001, num_epochs=30, resume_path=None):
    """
    è®­ç»ƒå­ªç”Ÿç½‘ç»œç”¨äºè™¹è†œéªŒè¯ï¼Œå¯ä»æŸä¸ªæ¨¡å‹æƒé‡ç»§ç»­è®­ç»ƒ
    
    å‚æ•°:
        learning_rate (float): å­¦ä¹ ç‡
        num_epochs (int): è®­ç»ƒè½®æ•°
        resume_path (str): å¦‚æœæä¾›ï¼ŒåŠ è½½è¿™ä¸ªè·¯å¾„çš„æ¨¡å‹å¹¶ç»§ç»­è®­ç»ƒ
    
    è¿”å›:
        è®­ç»ƒå¥½çš„æ¨¡å‹
    """
    train_loader, val_loader, test_loader = get_data_loaders(batch_size=32, val_split=0.1)
    
    model = SiameseNetwork()
    
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = ContrastiveLoss(margin=0.5)
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)
    
    # å˜—è©¦å¾resume_pathè¼‰å…¥æ¨¡å‹
    best_val_loss = float('inf')
    start_epoch = 0
    if resume_path and os.path.exists(resume_path):
        print(f"ğŸ” Resuming from checkpoint: {resume_path}")
        checkpoint = torch.load(resume_path, map_location=device)
        model.load_state_dict(checkpoint)
        # è‹¥ä½ æœ‰å„²å­˜ optimizer å’Œ epoch è³‡è¨Šï¼Œä¹Ÿå¯è¼‰å…¥é€™äº›ï¼ˆç›®å‰åƒ…è¼‰å…¥ modelï¼‰
    else:
        print("ğŸ†• Training from scratch.")

    train_losses, val_losses = [], []
    train_accs, val_accs = [], []

    for epoch in range(start_epoch, num_epochs):
        # === Training ===
        model.train()
        running_loss, correct, total = 0.0, 0, 0

        for img1, img2, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Train]"):
            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(img1, img2).squeeze()
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            predictions = (outputs > 0.5).float()
            total += labels.size(0)
            correct += (predictions == labels).sum().item()

        train_loss = running_loss / len(train_loader)
        train_acc = 100 * correct / total
        train_losses.append(train_loss)
        train_accs.append(train_acc)

        # === Validation ===
        model.eval()
        val_loss, correct, total = 0.0, 0, 0

        with torch.no_grad():
            for img1, img2, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Val]"):
                img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)
                outputs = model(img1, img2).squeeze()
                loss = criterion(outputs, labels)
                val_loss += loss.item()

                predictions = (outputs > 0.5).float()
                total += labels.size(0)
                correct += (predictions == labels).sum().item()

        val_loss /= len(val_loader)
        val_acc = 100 * correct / total
        val_losses.append(val_loss)
        val_accs.append(val_acc)

        scheduler.step(val_loss)

        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        # Save best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), r'D:\å®¶æ„·çš„è³‡æ–™\å¤§å­¸\å¤§ä¸‰\é›»è…¦è¦–è¦º\final\Ganzin_supplement4student\model\googlenet_50epoch.pth')
            print(f"ğŸ’¾ Model saved with validation loss: {best_val_loss:.4f}")



def verify_iris_images(model, img_path1, img_path2, threshold=0.8):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹éªŒè¯ä¸¤å¼ è™¹è†œå›¾åƒæ˜¯å¦å±äºåŒä¸€ä¸ªäºº
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„å­ªç”Ÿç½‘ç»œæ¨¡å‹
        img_path1: ç¬¬ä¸€å¼ å›¾åƒçš„è·¯å¾„
        img_path2: ç¬¬äºŒå¼ å›¾åƒçš„è·¯å¾„
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé«˜äºæ­¤å€¼åˆ™åˆ¤å®šä¸ºåŒä¸€ä¸ªäºº
    
    è¿”å›:
        æ˜¯å¦ä¸ºåŒä¸€ä¸ªäººçš„å¸ƒå°”å€¼ï¼Œç›¸ä¼¼åº¦åˆ†æ•°
    """
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()
    
    # å›¾åƒé¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½å›¾åƒ
    try:
        img1 = Image.open(img_path1).convert('RGB')
        img2 = Image.open(img_path2).convert('RGB')
    except Exception as e:
        print(f"Error loading images: {e}")
        return False, 0.0
    
    # åº”ç”¨è½¬æ¢
    img1 = transform(img1).unsqueeze(0).to(device)
    img2 = transform(img2).unsqueeze(0).to(device)
    
    # è·å–ç›¸ä¼¼åº¦å¾—åˆ†
    with torch.no_grad():
        similarity = model(img1, img2).item()
    if similarity > threshold:
        return 1
    else:
        return 0



if __name__ == "__main__":
    # æ£€æµ‹å¯ç”¨çš„è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # è®­ç»ƒå­ªç”Ÿç½‘ç»œ
    # model = train_siamese_network(num_epochs=40)
    model = train_siamese_network(num_epochs=10,resume_path=r'D:\å®¶æ„·çš„è³‡æ–™\å¤§å­¸\å¤§ä¸‰\é›»è…¦è¦–è¦º\final\Ganzin_supplement4student\model\googlenet_40epoch.pth')
    
    # ç¤ºä¾‹ï¼šéªŒè¯ä¸¤å¼ å›¾åƒ
    # ä½ å¯ä»¥æ›¿æ¢ä¸ºå®é™…çš„å›¾åƒè·¯å¾„
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    # model = SiameseNetwork()
    # model.load_state_dict(torch.load('best_siamese_iris.pth'))
    
    # ç¤ºä¾‹éªŒè¯
    # img_path1 = "path/to/image1.jpg"
    # img_path2 = "path/to/image2.jpg"
    # is_same, score = verify_iris_images(model, img_path1, img_path2)
    # print(f"Images belong to the same person: {is_same}")
    # print(f"Similarity score: {score:.4f}")